{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T01:57:11.529409Z",
     "iopub.status.busy": "2021-11-07T01:57:11.528742Z",
     "iopub.status.idle": "2021-11-07T01:57:11.533002Z",
     "shell.execute_reply": "2021-11-07T01:57:11.532163Z",
     "shell.execute_reply.started": "2021-11-07T01:57:11.529375Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "### one hot encode feature R and C and their combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T01:42:00.715506Z",
     "iopub.status.busy": "2021-11-07T01:42:00.715247Z",
     "iopub.status.idle": "2021-11-07T01:42:59.140727Z",
     "shell.execute_reply": "2021-11-07T01:42:59.140005Z",
     "shell.execute_reply.started": "2021-11-07T01:42:00.715477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "One hot encoding...\n",
      "Dropping id and labels...\n",
      "Normalizing...\n",
      "Reshaping...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler, normalize\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "masks=np.array(train['u_out']==0).reshape(-1, 80) # every 80 rows belongs to the same id\n",
    "targets = train[['pressure']].to_numpy().reshape(-1, 80)\n",
    "\n",
    "print(\"One hot encoding...\")\n",
    "for dset in ('train','test'):\n",
    "    df = eval(dset)\n",
    "    df['R'] = df['R'].astype(str)\n",
    "    df['C'] = df['C'].astype(str)\n",
    "    df = pd.get_dummies(df)\n",
    "    exec(f'{dset}=df')\n",
    "\n",
    "\n",
    "print(\"Dropping id and labels...\")\n",
    "train.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\n",
    "test = test.drop(['id', 'breath_id'], axis=1)\n",
    "\n",
    "print(\"Normalizing...\")\n",
    "RS = RobustScaler()\n",
    "train = RS.fit_transform(train)\n",
    "test = RS.transform(test)\n",
    "\n",
    "print(\"Reshaping...\")\n",
    "train = train.reshape(-1, 80, train.shape[-1])\n",
    "test = test.reshape(-1, 80, train.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (75450, 80, 9)\n",
      "test: (50300, 80, 9)\n"
     ]
    }
   ],
   "source": [
    "print('train:',train.shape)\n",
    "print('test:',test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T01:45:20.876353Z",
     "iopub.status.busy": "2021-11-07T01:45:20.876104Z",
     "iopub.status.idle": "2021-11-07T01:45:21.046778Z",
     "shell.execute_reply": "2021-11-07T01:45:21.046058Z",
     "shell.execute_reply.started": "2021-11-07T01:45:20.876326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67905 samples to train\n",
      " 7545 samples to validate\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10,random_state=0,shuffle=True)\n",
    "\n",
    "train_features=[train[i] for i in list(kf.split(train))[0][0]]\n",
    "val_features=[train[i] for i in list(kf.split(train))[0][1]]\n",
    "train_targets=[targets[i] for i in list(kf.split(targets))[0][0]]\n",
    "val_targets=[targets[i] for i in list(kf.split(targets))[0][1]]\n",
    "train_masks=[masks[i] for i in list(kf.split(targets))[0][0]]\n",
    "val_masks=[masks[i] for i in list(kf.split(targets))[0][1]]\n",
    "\n",
    "print(f\"{len(train_features):5d} samples to train\")\n",
    "print(f\"{len(val_features):5d} samples to validate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T01:47:01.301252Z",
     "iopub.status.busy": "2021-11-07T01:47:01.300679Z",
     "iopub.status.idle": "2021-11-07T01:47:01.311329Z",
     "shell.execute_reply": "2021-11-07T01:47:01.310674Z",
     "shell.execute_reply.started": "2021-11-07T01:47:01.301217Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "\n",
    "batch_size=128\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, features, targets, masks, train=True):\n",
    "        super(TrainDataset, self).__init__()\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.masks = masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index].astype('float32'),self.targets[index].astype('float32'),self.masks[index].astype('bool')\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, features): #HDKIM 100\n",
    "        super(TestDataset, self).__init__()\n",
    "        self.features = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        return self.features[index].astype('float32')\n",
    "\n",
    "train_dataset = TrainDataset(train_features,train_targets,train_masks)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "del train_features\n",
    "\n",
    "val_dataset = TrainDataset(val_features,val_targets,val_masks)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "del val_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T01:48:50.792871Z",
     "iopub.status.busy": "2021-11-07T01:48:50.792548Z",
     "iopub.status.idle": "2021-11-07T01:48:50.815275Z",
     "shell.execute_reply": "2021-11-07T01:48:50.814578Z",
     "shell.execute_reply.started": "2021-11-07T01:48:50.792836Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class PosEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, embd_dim, rnn='GRU'):\n",
    "        assert rnn in ('GRU','LSTM'), 'rnn must be either GRU or LSTM'\n",
    "        super(PosEncoder, self).__init__()\n",
    "        exec(f\"self.rnn = nn.{rnn}(embd_dim,embd_dim,num_layers=1,bidirectional=True)\")\n",
    "        self.mlp = nn.Sequential(nn.Linear(embd_dim*2, 1024), # if not bidirecional, use embd instead of embd * 2\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(1024, embd_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x+self.mlp(self.rnn(x)[0])\n",
    "    \n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, max_seq=100, embd_dim=128, \n",
    "                 rnn_type = 'GRU',n_rnn_layers=2,\n",
    "                 n_transformer_layers=6, dropout=0, nheads=8, \n",
    "                 use_conv=False):\n",
    "        \n",
    "        super(MyModel, self).__init__()\n",
    "        self.use_conv = use_conv\n",
    "        \n",
    "        # embedding layer\n",
    "        self.embedding = nn.Linear(in_dim, embd_dim)\n",
    "        \n",
    "        # trainable positional encoder\n",
    "        self.pos_encoder = nn.ModuleList([PosEncoder(embd_dim,rnn=rnn_type) \n",
    "                                          for i in range(n_rnn_layers)])\n",
    "        self.pos_encoder_dropout = nn.Dropout(dropout)\n",
    "        self.pos_encoder_ln = nn.LayerNorm(embd_dim)\n",
    "        \n",
    "        # transformer layers\n",
    "        transformer_layers = [nn.TransformerEncoderLayer(embd_dim, nhead=nheads, dropout=dropout) \n",
    "                              for i in range(n_transformer_layers)]\n",
    "        self.transformer_layers = nn.ModuleList(transformer_layers)\n",
    "        self.downsample = nn.Linear(embd_dim*2,embd_dim) \n",
    "        self.clf = nn.Linear(embd_dim, out_dim)\n",
    "        \n",
    "        # optional conv and deconv layers\n",
    "        if self.use_conv:\n",
    "            nlayers = n_transformer_layers\n",
    "            self.conv_layers = nn.ModuleList([\n",
    "                                                nn.Conv1d(embd_dim,embd_dim,\n",
    "                                                         (nlayers-i)*2-1,stride=1,padding=0) \n",
    "                                                for i in range(nlayers)\n",
    "                                                ])\n",
    "            \n",
    "            self.conv_ln = nn.ModuleList([nn.LayerNorm(embd_dim) for i in range(nlayers)])\n",
    "            \n",
    "            self.deconv_layers = nn.ModuleList([\n",
    "                                                nn.ConvTranspose1d(embd_dim,embd_dim,\n",
    "                                                                   (nlayers-i)*2-1,stride=1,padding=0) \n",
    "                                                for i in range(nlayers)\n",
    "                                                ])\n",
    "            self.deconv_ln = nn.ModuleList([nn.LayerNorm(embd_dim) for i in range(nlayers)])\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        x=self.embedding(x)\n",
    "        x = x.permute(1, 0, 2) # (L,N,feature_dim)\n",
    "        \n",
    "        for pos_encoder_layer in self.pos_encoder:\n",
    "            pos_encoder_layer.rnn.flatten_parameters()\n",
    "            x=pos_encoder_layer(x)\n",
    "\n",
    "        x = self.pos_encoder_dropout(x)\n",
    "        x = self.pos_encoder_ln(x)\n",
    "        \n",
    "        if not self.use_conv:\n",
    "            for transformer_layer in self.transformer_layers:\n",
    "                x = transformer_layer(x)\n",
    "        else:\n",
    "            enhanced_transformer_layers = zip(self.conv_layers,self.conv_ln,\n",
    "                                              self.transformer_layers,\n",
    "                                              self.deconv_layers,self.deconv_ln)\n",
    "            for conv, convln, transformer_layer, deconv, deconvln in enhanced_transformer_layers:\n",
    "                x_ = convln(F.relu(conv(x.permute(1,2,0)).permute(2,0,1)))\n",
    "                x_ = transformer_layer(x_)\n",
    "                x_ = deconvln(F.relu(deconv(x_.permute(1,2,0)).permute(2,0,1)))\n",
    "                x += x_\n",
    "                \n",
    "\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        output = self.clf(x)\n",
    "\n",
    "        return output.squeeze(-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T01:49:00.711446Z",
     "iopub.status.busy": "2021-11-07T01:49:00.711174Z",
     "iopub.status.idle": "2021-11-07T01:49:05.936185Z",
     "shell.execute_reply": "2021-11-07T01:49:05.935179Z",
     "shell.execute_reply.started": "2021-11-07T01:49:00.711418Z"
    }
   },
   "outputs": [],
   "source": [
    "model = MyModel(in_dim = train.shape[-1], out_dim = 1,embd_dim=128,\n",
    "                n_transformer_layers=6, nheads = 8, dropout=0,\n",
    "                n_rnn_layers=2, rnn_type = 'GRU',use_conv = True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (embedding): Linear(in_features=9, out_features=128, bias=True)\n",
       "  (pos_encoder): ModuleList(\n",
       "    (0): PosEncoder(\n",
       "      (rnn): GRU(128, 128, bidirectional=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): PosEncoder(\n",
       "      (rnn): GRU(128, 128, bidirectional=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pos_encoder_dropout): Dropout(p=0, inplace=False)\n",
       "  (pos_encoder_ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (transformer_layers): ModuleList(\n",
       "    (0): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0, inplace=False)\n",
       "      (dropout2): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0, inplace=False)\n",
       "      (dropout2): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0, inplace=False)\n",
       "      (dropout2): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0, inplace=False)\n",
       "      (dropout2): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0, inplace=False)\n",
       "      (dropout2): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0, inplace=False)\n",
       "      (dropout2): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (downsample): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (clf): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (conv_layers): ModuleList(\n",
       "    (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,))\n",
       "    (1): Conv1d(128, 128, kernel_size=(9,), stride=(1,))\n",
       "    (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,))\n",
       "    (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
       "    (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "    (5): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (conv_ln): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (deconv_layers): ModuleList(\n",
       "    (0): ConvTranspose1d(128, 128, kernel_size=(11,), stride=(1,))\n",
       "    (1): ConvTranspose1d(128, 128, kernel_size=(9,), stride=(1,))\n",
       "    (2): ConvTranspose1d(128, 128, kernel_size=(7,), stride=(1,))\n",
       "    (3): ConvTranspose1d(128, 128, kernel_size=(5,), stride=(1,))\n",
       "    (4): ConvTranspose1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "    (5): ConvTranspose1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (deconv_ln): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T01:53:46.099652Z",
     "iopub.status.busy": "2021-11-07T01:53:46.09939Z",
     "iopub.status.idle": "2021-11-07T01:53:52.991752Z",
     "shell.execute_reply": "2021-11-07T01:53:52.990931Z",
     "shell.execute_reply.started": "2021-11-07T01:53:46.099624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_ranger in /home/jamestuna/anaconda3/lib/python3.8/site-packages (0.1.1)\r\n",
      "Requirement already satisfied: torch in /home/jamestuna/anaconda3/lib/python3.8/site-packages (from pytorch_ranger) (1.9.0)\r\n",
      "Requirement already satisfied: typing_extensions in /home/jamestuna/anaconda3/lib/python3.8/site-packages (from torch->pytorch_ranger) (3.7.4.3)\r\n"
     ]
    }
   ],
   "source": [
    "#install ranger optimizer\n",
    "#! git clone https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer\n",
    "#! pip install -e Ranger-Deep-Learning-Optimizer\n",
    "! pip install pytorch_ranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T01:54:14.635046Z",
     "iopub.status.busy": "2021-11-07T01:54:14.634585Z",
     "iopub.status.idle": "2021-11-07T01:54:14.641107Z",
     "shell.execute_reply": "2021-11-07T01:54:14.640393Z",
     "shell.execute_reply.started": "2021-11-07T01:54:14.635011Z"
    }
   },
   "outputs": [],
   "source": [
    "#optimizer and criterion\n",
    "from pytorch_ranger import Ranger\n",
    "optimizer = Ranger(model.parameters(), lr=8e-4)\n",
    "criterion = nn.L1Loss(reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(comment='smallfs_modelsmall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T01:55:54.485659Z",
     "iopub.status.busy": "2021-11-07T01:55:54.485391Z",
     "iopub.status.idle": "2021-11-07T01:55:54.490837Z",
     "shell.execute_reply": "2021-11-07T01:55:54.490013Z",
     "shell.execute_reply.started": "2021-11-07T01:55:54.485628Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = Ranger(model.parameters(), lr=8e-5)\n",
    "epochs=150\n",
    "val_metric = 100\n",
    "best_metric = 100\n",
    "cos_epoch=int(epochs*0.75)\n",
    "scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,(epochs-cos_epoch)*len(train_dataloader))\n",
    "steps_per_epoch=len(train_dataloader)\n",
    "val_steps=len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T01:58:55.000715Z",
     "iopub.status.busy": "2021-11-07T01:58:55.000385Z",
     "iopub.status.idle": "2021-11-07T02:01:01.286303Z",
     "shell.execute_reply": "2021-11-07T02:01:01.285248Z",
     "shell.execute_reply.started": "2021-11-07T01:58:55.000679Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [3/531] Loss: 17.873 Time: 0.7\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamestuna/anaconda3/lib/python3.8/site-packages/pytorch_ranger/ranger.py:172: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/torch/csrc/utils/python_arg_parser.cpp:1025.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [116/531] Loss: 9.015 Time: 7.7\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d6ceddab2fbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m#exit()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#exit()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-13e3a8d7d5b6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpos_encoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mpos_encoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_encoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoder_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-13e3a8d7d5b6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    838\u001b[0m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    839\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss=0\n",
    "    t=time.time()\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "        #series=batch.to(device)#.float()\n",
    "        features,targets,mask=batch\n",
    "        features=features.cuda()\n",
    "        targets=targets.cuda()\n",
    "        mask=mask.cuda()\n",
    "        #exit()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output=model(features)\n",
    "        #exit()\n",
    "        #exit()\n",
    "\n",
    "        loss=criterion(output,targets)#*loss_weight_vector\n",
    "        loss=torch.masked_select(loss,mask)\n",
    "        loss=loss.mean()\n",
    "        loss.backward()\n",
    "        # with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        #     scaled_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss+=loss.item()\n",
    "        #scheduler.step()\n",
    "        print (\"Step [{}/{}] Loss: {:.3f} Time: {:.1f}\"\n",
    "                           .format(step+1, steps_per_epoch, train_loss/(step+1), time.time()-t),end='\\r',flush=True)\n",
    "        if epoch > cos_epoch:\n",
    "            scheduler.step()\n",
    "        #break\n",
    "    print('')\n",
    "    train_loss/=(step+1)\n",
    "    \n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "\n",
    "    #exit()\n",
    "    model.eval()\n",
    "    val_metric=[]\n",
    "    val_loss=0\n",
    "    t=time.time()\n",
    "    preds=[]\n",
    "    truths=[]\n",
    "    masks=[]\n",
    "    for step,batch in enumerate(val_dataloader):\n",
    "        features,targets,mask=batch\n",
    "        features=features.cuda()\n",
    "        targets=targets.cuda()\n",
    "        mask=mask.cuda()\n",
    "        with torch.no_grad():\n",
    "            output=model(features)\n",
    "\n",
    "            loss=criterion(output,targets)\n",
    "            loss=torch.masked_select(loss,mask)\n",
    "            loss=loss.mean()\n",
    "            val_loss+=loss.item()\n",
    "            preds.append(output.cpu())\n",
    "            truths.append(targets.cpu())\n",
    "            masks.append(mask.cpu())\n",
    "        print (\"Validation Step [{}/{}] Loss: {:.3f} Time: {:.1f}\"\n",
    "                           .format(step+1, val_steps, val_loss/(step+1), time.time()-t),end='\\r',flush=True)\n",
    "\n",
    "    preds=torch.cat(preds).numpy()\n",
    "    truths=torch.cat(truths).numpy()\n",
    "    masks=torch.cat(masks).numpy()\n",
    "    val_metric=(np.abs(truths-preds)*masks).sum()/masks.sum()#*stds['pressure']\n",
    "    print('')\n",
    "    val_loss/=(step+1)\n",
    "    writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "\n",
    "\n",
    "    if val_metric < best_metric:\n",
    "        best_metric=val_metric\n",
    "        torch.save(model.state_dict(),'smallfs_modelsmall.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
